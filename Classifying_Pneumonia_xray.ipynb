{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습용 정상인 폐사진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=[]\n",
    "path='/Users/suminbae/Python-Workspace/kaggle/chest_xray/train/NORMAL/*.jpeg'\n",
    "\n",
    "for filename in glob.glob(path):\n",
    "    im=Image.open(filename).convert('L') # convert('L') - converts RGB images (if any) to grayscale\n",
    "    img = im.resize((100, 100)) \n",
    "    train_x.append(tf.keras.preprocessing.image.img_to_array(img))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=len(train_x)\n",
    "train_y=np.zeros(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습용 폐렴 사진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/Users/suminbae/Python-Workspace/kaggle/chest_xray/train/PNEUMONIA//*.jpeg'\n",
    "\n",
    "for filename in glob.glob(path):\n",
    "    im=Image.open(filename).convert('L')\n",
    "    img=im.resize((100,100))\n",
    "    train_x.append(tf.keras.preprocessing.image.img_to_array(img))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=len(train_x)\n",
    "train_y=np.concatenate((train_y,np.ones(b-a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=np.stack(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가용 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x=[]\n",
    "path='/Users/suminbae/Python-Workspace/kaggle/chest_xray/val/NORMAL/*.jpeg'\n",
    "\n",
    "for filename in glob.glob(path):\n",
    "    im=Image.open(filename).convert('L') # convert('L') - converts RGB images (if any) to grayscale\n",
    "    img = im.resize((100, 100)) \n",
    "    val_x.append(tf.keras.preprocessing.image.img_to_array(img))\n",
    "\n",
    "c=len(val_x)    \n",
    "val_y=np.zeros(c)\n",
    "    \n",
    "path2='/Users/suminbae/Python-Workspace/kaggle/chest_xray/val/PNEUMONIA/*.jpeg'\n",
    "\n",
    "for filename in glob.glob(path2):\n",
    "    im=Image.open(filename).convert('L') # convert('L') - converts RGB images (if any) to grayscale\n",
    "    img = im.resize((100, 100)) \n",
    "    val_x.append(tf.keras.preprocessing.image.img_to_array(img))\n",
    "    \n",
    "d=len(val_x)\n",
    "val_y=np.concatenate((val_y,np.ones(d-c)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x=np.stack(val_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트용 데이터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=[]\n",
    "path='/Users/suminbae/Python-Workspace/kaggle/chest_xray/test/NORMAL/*.jpeg'\n",
    "\n",
    "for filename in glob.glob(path):\n",
    "    im=Image.open(filename).convert('L') # convert('L') - converts RGB images (if any) to grayscale\n",
    "    img = im.resize((100, 100)) \n",
    "    test_x.append(tf.keras.preprocessing.image.img_to_array(img))\n",
    "    \n",
    "    \n",
    "a=len(test_x)\n",
    "test_y=np.zeros(a)\n",
    "\n",
    "\n",
    "path2='/Users/suminbae/Python-Workspace/kaggle/chest_xray/test/PNEUMONIA/*.jpeg'\n",
    "\n",
    "for filename in glob.glob(path2):\n",
    "    im=Image.open(filename).convert('L') # convert('L') - converts RGB images (if any) to grayscale\n",
    "    img = im.resize((100, 100)) \n",
    "    test_x.append(tf.keras.preprocessing.image.img_to_array(img))\n",
    "    \n",
    "\n",
    "b=len(test_x)\n",
    "test_y=np.concatenate((test_y,np.ones(b-a)))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=np.stack(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5216, 100, 100, 1), (16, 100, 100, 1), (624, 100, 100, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,val_x.shape,test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx,vx,ty,vy=train_test_split(train_x,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential([\n",
    "    layers.Conv2D(filters=60,kernel_size=(3,3),activation='relu',padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(4,4)),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Conv2D(filters=40,kernel_size=(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(8,8)),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512,activation='relu'),\n",
    "    layers.Dense(128,activation='relu'),\n",
    "    layers.Dense(1,activation='sigmoid')\n",
    "    \n",
    "    \n",
    "])\n",
    "\n",
    "es=tf.keras.callbacks.EarlyStopping(monitor='loss',patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.compile(loss=\"binary_crossentropy\",optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3912 samples, validate on 1304 samples\n",
      "Epoch 1/15\n",
      "3912/3912 [==============================] - 28s 7ms/sample - loss: 0.6125 - acc: 0.7326 - val_loss: 0.6839 - val_acc: 0.7446\n",
      "Epoch 2/15\n",
      "3912/3912 [==============================] - 28s 7ms/sample - loss: 0.5755 - acc: 0.7385 - val_loss: 0.6731 - val_acc: 0.7331\n",
      "Epoch 3/15\n",
      "3912/3912 [==============================] - 28s 7ms/sample - loss: 0.5467 - acc: 0.7485 - val_loss: 0.6385 - val_acc: 0.7538\n",
      "Epoch 4/15\n",
      "3912/3912 [==============================] - 28s 7ms/sample - loss: 0.5151 - acc: 0.7635 - val_loss: 0.5819 - val_acc: 0.8144\n",
      "Epoch 5/15\n",
      "3912/3912 [==============================] - 28s 7ms/sample - loss: 0.4444 - acc: 0.7922 - val_loss: 0.5051 - val_acc: 0.8459\n",
      "Epoch 6/15\n",
      "3912/3912 [==============================] - 28s 7ms/sample - loss: 0.3800 - acc: 0.8344 - val_loss: 0.4163 - val_acc: 0.8359\n",
      "Epoch 7/15\n",
      "3912/3912 [==============================] - 28s 7ms/sample - loss: 0.3529 - acc: 0.8428 - val_loss: 0.4382 - val_acc: 0.8581\n",
      "Epoch 8/15\n",
      "3912/3912 [==============================] - 28s 7ms/sample - loss: 0.3257 - acc: 0.8571 - val_loss: 0.4060 - val_acc: 0.8827\n",
      "Epoch 9/15\n",
      "3912/3912 [==============================] - 29s 7ms/sample - loss: 0.2932 - acc: 0.8786 - val_loss: 0.3503 - val_acc: 0.8850\n",
      "Epoch 10/15\n",
      "3912/3912 [==============================] - 29s 8ms/sample - loss: 0.2807 - acc: 0.8768 - val_loss: 0.3031 - val_acc: 0.8880\n",
      "Epoch 11/15\n",
      "3912/3912 [==============================] - 28s 7ms/sample - loss: 0.2764 - acc: 0.8814 - val_loss: 0.3294 - val_acc: 0.8980\n",
      "Epoch 12/15\n",
      "3912/3912 [==============================] - 30s 8ms/sample - loss: 0.2701 - acc: 0.8842 - val_loss: 0.2879 - val_acc: 0.9095\n",
      "Epoch 13/15\n",
      "3912/3912 [==============================] - 30s 8ms/sample - loss: 0.2470 - acc: 0.8954 - val_loss: 0.2864 - val_acc: 0.9172\n",
      "Epoch 14/15\n",
      "3912/3912 [==============================] - 29s 7ms/sample - loss: 0.2410 - acc: 0.8916 - val_loss: 0.3344 - val_acc: 0.9026\n",
      "Epoch 15/15\n",
      "3912/3912 [==============================] - 32s 8ms/sample - loss: 0.2755 - acc: 0.8875 - val_loss: 0.2497 - val_acc: 0.9256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd1aad68a10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tx,ty,validation_data=(vx,vy),batch_size=300,epochs=15,callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 대략 80퍼센트의 정확성을 가진다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 1s 2ms/sample - loss: 0.4232 - acc: 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4232405152840492, 0.8125]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('pre',train_x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://github.com/siddarth-c/MachineLearning/blob/master/DeepLearning/PNEUMONIA%20or%20NOT.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
